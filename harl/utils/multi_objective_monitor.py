
import numpy as np
import torch
from collections import deque
from typing import Dict, Optional, Tuple, Any, List
import warnings
import os
warnings.filterwarnings('ignore')


class MultiObjectiveMonitor:
    """å¤šç›®æ ‡ç›‘æµ‹å™¨ - ä¿æŒåŸç‰ˆæœ¬é€»è¾‘ï¼Œå¢åŠ å½±å“åˆ†æ"""

    def __init__(self, writer, monitor_freq: int = 5, save_dir: str = None):
        self.writer = writer
        self.monitor_freq = monitor_freq
        self.update_count = 0
        self.save_dir = save_dir

        # å¥–åŠ±åˆ†é‡åç§°
        self.components = ['safety', 'efficiency', 'stability', 'comfort']

        # ğŸ” æ–°å¢ï¼šå®šä¹‰æ‰€æœ‰äº¤å‰é¡¹å¯¹
        self.component_pairs = [
            ('safety', 'efficiency'),
            ('safety', 'stability'),
            ('safety', 'comfort'),
            ('efficiency', 'stability'),
            ('efficiency', 'comfort'),
            ('stability', 'comfort')
        ]

        # å†å²æ•°æ®å­˜å‚¨
        self.history_len = 50
        self.reward_history = {comp: deque(maxlen=self.history_len) for comp in self.components}
        self.value_history = {comp: deque(maxlen=self.history_len) for comp in self.components}
        self.advantage_history = {comp: deque(maxlen=self.history_len) for comp in self.components}
        self.loss_history = {comp: deque(maxlen=self.history_len) for comp in self.components}
        self.weight_history = {comp: deque(maxlen=self.history_len) for comp in self.components}

        # ğŸ” æ–°å¢ï¼šç›¸å…³æ€§å†å²å­˜å‚¨
        self.correlation_history = {
            f"{pair[0]}_{pair[1]}": deque(maxlen=self.history_len)
            for pair in self.component_pairs
        }

        # å†²çªæ£€æµ‹é˜ˆå€¼
        self.conflict_threshold = -0.3
        self.severe_conflict_threshold = -0.7

        # çŠ¶æ€å˜é‡
        self.latest_conflicts = 0
        self.latest_severe_conflicts = 0
        self.latest_clarity_score = 0.5

        # å½“å‰ç›¸å…³æ€§è®°å½•
        self.current_correlations = {}

        # å½±å“åˆ†æç›¸å…³å˜é‡
        self.impact_metrics = {
            'value_divergence_ratio': 0.0,
            'advantage_conflict_ratio': 0.0,
            'loss_instability_ratio': 0.0,
            'gradient_interference_ratio': 0.0,
            'overall_impact_ratio': 0.0
        }

        # CSVæ–‡ä»¶åˆå§‹åŒ–
        if self.save_dir:
            self.correlation_csv_path = os.path.join(self.save_dir, 'correlation_history.csv')
            self._init_correlation_csv()

        print("âœ… Multi-objective monitoring initialized")

    @classmethod
    def create(cls, writer, monitor_freq: int = 5, save_dir: str = None):
        """åˆ›å»ºç›‘æµ‹å™¨å®ä¾‹"""
        try:
            return cls(writer, monitor_freq, save_dir)
        except Exception as e:
            print(f"âš ï¸ Failed to create multi-objective monitor: {e}")
            return DummyMonitor()

    def _init_correlation_csv(self):
        """åˆå§‹åŒ–ç›¸å…³æ€§CSVæ–‡ä»¶"""
        try:
            import csv
            with open(self.correlation_csv_path, 'w', newline='') as csvfile:
                writer = csv.writer(csvfile)
                # CSVè¡¨å¤´
                headers = ['timestep', 'episode']
                for pair in self.component_pairs:
                    headers.append(f"{pair[0]}_vs_{pair[1]}_correlation")
                    headers.append(f"{pair[0]}_vs_{pair[1]}_conflict_level")
                headers.extend(['total_conflicts', 'severe_conflicts', 'overall_impact'])
                writer.writerow(headers)
        except Exception as e:
            print(f"âš ï¸ Error initializing correlation CSV: {e}")

    def _save_correlations_to_csv(self, timestep: int, episode: int):
        """ä¿å­˜ç›¸å…³æ€§æ•°æ®åˆ°CSV"""
        try:
            import csv
            with open(self.correlation_csv_path, 'a', newline='') as csvfile:
                writer = csv.writer(csvfile)
                row = [timestep, episode]

                for pair in self.component_pairs:
                    pair_key = f"{pair[0]}_{pair[1]}"
                    correlation = self.current_correlations.get(pair_key, 0.0)

                    # åˆ¤æ–­å†²çªçº§åˆ«
                    if correlation < self.severe_conflict_threshold:
                        conflict_level = 'severe'
                    elif correlation < self.conflict_threshold:
                        conflict_level = 'moderate'
                    else:
                        conflict_level = 'none'

                    row.extend([correlation, conflict_level])

                row.extend([
                    self.latest_conflicts,
                    self.latest_severe_conflicts,
                    self.impact_metrics.get('overall_impact_ratio', 0.0)
                ])
                writer.writerow(row)

        except Exception as e:
            print(f"âš ï¸ Error saving correlations to CSV: {e}")

    def should_monitor(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç›‘æµ‹"""
        return self.update_count % self.monitor_freq == 0

    def extract_component_data(self, actor_buffer_list) -> Tuple[Dict[str, np.ndarray], Optional[np.ndarray]]:
        """ä»actor bufferä¸­æå–åˆ†é‡å¥–åŠ±å’Œæƒé‡æ•°æ®"""
        try:
            rewards_data = {}
            weights = None

            if not actor_buffer_list:
                return rewards_data, weights

            buffer = actor_buffer_list[0]

            # æå–åˆ†é‡å¥–åŠ±
            reward_fields = {
                'safety': ['rewards_safety', 'safety_rewards', 'reward_safety'],
                'efficiency': ['rewards_efficiency', 'efficiency_rewards', 'reward_efficiency'],
                'stability': ['rewards_stability', 'stability_rewards', 'reward_stability'],
                'comfort': ['rewards_comfort', 'comfort_rewards', 'reward_comfort']
            }

            for comp, field_names in reward_fields.items():
                for field_name in field_names:
                    if hasattr(buffer, field_name):
                        rewards_data[comp] = getattr(buffer, field_name)
                        break

            # æå–æƒé‡
            weight_fields = ['rewards_weights', 'reward_weights', 'weights']
            for field_name in weight_fields:
                if hasattr(buffer, field_name):
                    weights = getattr(buffer, field_name)
                    break

            return rewards_data, weights

        except Exception as e:
            print(f"âš ï¸ Error extracting component data: {e}")
            return {}, None

    def compute_component_returns_and_advantages(self,
                                               rewards_data: Dict[str, np.ndarray],
                                               critic_buffer,
                                               weights: Optional[np.ndarray] = None) -> Tuple[Dict, Dict, Dict]:
        """çœŸæ­£è®¡ç®—å„åˆ†é‡rewardå¯¹åº”çš„returnsã€valueså’Œadvantages"""
        component_returns = {}
        component_values = {}
        component_advantages = {}

        try:
            # è·å–critic bufferçš„å…³é”®å‚æ•°
            gamma = getattr(critic_buffer, 'gamma', 0.99)
            gae_lambda = getattr(critic_buffer, 'gae_lambda', 0.95)
            use_gae = getattr(critic_buffer, 'use_gae', True)
            masks = getattr(critic_buffer, 'masks', None)

            # è·å–æ€»ä½“value predictions
            total_value_preds = critic_buffer.value_preds[:-1] if hasattr(critic_buffer, 'value_preds') else None

            # æ£€æŸ¥total_value_predsçš„æœ‰æ•ˆæ€§
            if total_value_preds is not None:
                if np.any(np.isnan(total_value_preds)) or np.any(np.isinf(total_value_preds)):
                    print(f"âš ï¸ NaN/Inf in total_value_preds, using simplified values")
                    total_value_preds = None

            for comp_idx, comp in enumerate(self.components):
                if comp not in rewards_data:
                    continue

                comp_rewards = rewards_data[comp]  # [episode_length, n_threads, 1]

                # æ£€æŸ¥å¥–åŠ±æ•°æ®æœ‰æ•ˆæ€§
                if np.any(np.isnan(comp_rewards)) or np.any(np.isinf(comp_rewards)):
                    print(f"âš ï¸ NaN/Inf in {comp} rewards, skipping")
                    continue

                # ğŸ” å…³é”®ï¼šçœŸæ­£è®¡ç®—å„åˆ†é‡çš„returns
                comp_returns = self._compute_component_returns(
                    comp_rewards, gamma, gae_lambda, use_gae, masks,
                    weights, comp_idx if weights is not None else None
                )

                # æ£€æŸ¥returnsçš„æœ‰æ•ˆæ€§
                if np.any(np.isnan(comp_returns)) or np.any(np.isinf(comp_returns)):
                    print(f"âš ï¸ NaN/Inf in {comp} returns, using simplified calculation")
                    comp_returns = np.mean(comp_rewards) * np.ones_like(comp_rewards)

                # ğŸ” å…³é”®ï¼šä¼°ç®—å„åˆ†é‡å¯¹æ€»ä½“valueçš„è´¡çŒ®
                if total_value_preds is not None and weights is not None and comp_idx < weights.shape[-1]:
                    # æ–¹æ³•1: æŒ‰æƒé‡æ¯”ä¾‹åˆ†é…value
                    weight_ratio = weights[:, :, comp_idx:comp_idx+1] / (weights.sum(axis=-1, keepdims=True) + 1e-8)
                    comp_values = total_value_preds * weight_ratio
                elif total_value_preds is not None:
                    # æ–¹æ³•2: æŒ‰å¥–åŠ±æ¯”ä¾‹ä¼°ç®—valueè´¡çŒ®
                    all_rewards_sum = sum(np.mean(rewards_data[c]) for c in rewards_data.keys())
                    comp_reward_ratio = np.mean(comp_rewards) / (all_rewards_sum + 1e-8)
                    comp_values = total_value_preds * comp_reward_ratio
                else:
                    # æ–¹æ³•3: ç®€åŒ–ä¼°ç®— - ä½¿ç”¨å¥–åŠ±å‡å€¼ä½œä¸ºvalueä¼°ç®—
                    comp_mean_reward = np.mean(comp_rewards)
                    comp_values = np.full_like(comp_returns, comp_mean_reward)

                # æ£€æŸ¥valuesçš„æœ‰æ•ˆæ€§
                if np.any(np.isnan(comp_values)) or np.any(np.isinf(comp_values)):
                    print(f"âš ï¸ NaN/Inf in {comp} values, using mean reward")
                    comp_values = np.full_like(comp_returns, np.mean(comp_rewards))

                # å…³é”®ï¼šè®¡ç®—å„åˆ†é‡çš„çœŸå®advantage
                comp_advantages = comp_returns - comp_values

                # æ£€æŸ¥advantagesçš„æœ‰æ•ˆæ€§
                if np.any(np.isnan(comp_advantages)) or np.any(np.isinf(comp_advantages)):
                    print(f"âš ï¸ NaN/Inf in {comp} advantages, using simplified calculation")
                    comp_advantages = comp_returns * 0.1  # ç®€åŒ–ï¼šå‡è®¾advantageæ˜¯returnsçš„10%

                component_returns[comp] = comp_returns
                component_values[comp] = comp_values
                component_advantages[comp] = comp_advantages

            return component_returns, component_values, component_advantages

        except Exception as e:
            print(f"âš ï¸ Error computing component returns and advantages: {e}")
            return {}, {}, {}

    def _compute_component_returns(self,
                                  comp_rewards: np.ndarray,
                                  gamma: float,
                                  gae_lambda: float,
                                  use_gae: bool,
                                  masks: Optional[np.ndarray],
                                  weights: Optional[np.ndarray] = None,
                                  comp_idx: Optional[int] = None) -> np.ndarray:
        """ä¸ºå•ä¸ªåˆ†é‡è®¡ç®—returns"""
        try:
            episode_length, n_threads = comp_rewards.shape[0], comp_rewards.shape[1]

            # æ£€æŸ¥è¾“å…¥æ•°æ®çš„æœ‰æ•ˆæ€§
            if np.any(np.isnan(comp_rewards)) or np.any(np.isinf(comp_rewards)):
                print(f"âš ï¸ NaN/Inf in component rewards, using zeros")
                return np.zeros_like(comp_rewards)

            # åº”ç”¨æƒé‡ï¼ˆå¦‚æœæœ‰ï¼‰
            if weights is not None and comp_idx is not None and comp_idx < weights.shape[-1]:
                weight_slice = weights[:, :, comp_idx:comp_idx+1]
                # æ£€æŸ¥æƒé‡æœ‰æ•ˆæ€§
                if np.any(np.isnan(weight_slice)) or np.any(np.isinf(weight_slice)):
                    print(f"âš ï¸ NaN/Inf in weights, using original rewards")
                    weighted_rewards = comp_rewards
                else:
                    weighted_rewards = comp_rewards * weight_slice
            else:
                weighted_rewards = comp_rewards

            # å†æ¬¡æ£€æŸ¥åŠ æƒåçš„å¥–åŠ±
            if np.any(np.isnan(weighted_rewards)) or np.any(np.isinf(weighted_rewards)):
                print(f"âš ï¸ NaN/Inf in weighted rewards, using original")
                weighted_rewards = comp_rewards

            # åˆå§‹åŒ–returns
            returns = np.zeros_like(weighted_rewards)

            # ç®€åŒ–è¿”å›è®¡ç®—ï¼Œé¿å…å¤æ‚çš„GAEå¯¼è‡´NaN
            # ä½¿ç”¨ç®€å•çš„ç´¯ç§¯æŠ˜æ‰£å¥–åŠ±
            returns[-1] = weighted_rewards[-1]
            for step in reversed(range(episode_length - 1)):
                next_return = returns[step + 1]
                current_return = weighted_rewards[step] + gamma * next_return

                # æ£€æŸ¥è®¡ç®—ç»“æœ
                if np.any(np.isnan(current_return)) or np.any(np.isinf(current_return)):
                    current_return = weighted_rewards[step]  # å¦‚æœå‡ºç°NaNï¼Œåªä½¿ç”¨å½“å‰å¥–åŠ±

                returns[step] = current_return

                # åº”ç”¨mask
                if masks is not None and step < masks.shape[0] - 1:
                    mask_slice = masks[step + 1, :, :]
                    if not (np.any(np.isnan(mask_slice)) or np.any(np.isinf(mask_slice))):
                        returns[step] = returns[step] * mask_slice

            # æœ€ç»ˆæ£€æŸ¥
            if np.any(np.isnan(returns)) or np.any(np.isinf(returns)):
                print(f"âš ï¸ NaN/Inf in final returns, using simplified calculation")
                returns = np.cumsum(weighted_rewards[::-1], axis=0)[::-1]  # ç®€å•ç´¯ç§¯

            return returns

        except Exception as e:
            print(f"âš ï¸ Error computing component returns: {e}")
            return np.zeros_like(comp_rewards)

    def compute_component_losses(self, component_advantages: Dict[str, np.ndarray]) -> Dict[str, float]:
        """è®¡ç®—å„åˆ†é‡å¯¹åº”çš„ç­–ç•¥æŸå¤±"""
        component_losses = {}

        try:
            for comp, comp_advantages in component_advantages.items():
                # æ£€æŸ¥advantageçš„æœ‰æ•ˆæ€§
                if np.any(np.isnan(comp_advantages)) or np.any(np.isinf(comp_advantages)):
                    print(f"âš ï¸ NaN/Inf in {comp} advantages for loss calculation")
                    component_losses[comp] = 0.0
                    continue

                # ä½¿ç”¨advantageçš„è´Ÿå‡å€¼ä½œä¸ºæŸå¤±æŒ‡æ ‡
                comp_loss = -np.mean(comp_advantages)

                # æ£€æŸ¥æŸå¤±çš„æœ‰æ•ˆæ€§
                if np.isnan(comp_loss) or np.isinf(comp_loss):
                    print(f"âš ï¸ NaN/Inf in {comp} loss calculation")
                    comp_loss = 0.0

                component_losses[comp] = float(comp_loss)

            return component_losses

        except Exception as e:
            print(f"âš ï¸ Error computing component losses: {e}")
            return {}

    def detect_conflicts(self, component_advantages: Dict[str, np.ndarray], verbose: bool = False) -> bool:
        """åŸºäºçœŸå®çš„å„åˆ†é‡advantageæ£€æµ‹å†²çª - è¾“å‡ºæ‰€æœ‰äº¤å‰é¡¹ç›¸å…³æ€§"""
        try:
            if len(component_advantages) < 2:
                return False

            # æ„å»ºadvantageçŸ©é˜µè¿›è¡Œç›¸å…³æ€§åˆ†æ
            advantage_means = []
            comp_names = []

            for comp, advantages in component_advantages.items():
                # æ£€æŸ¥advantageçš„æœ‰æ•ˆæ€§
                if np.any(np.isnan(advantages)) or np.any(np.isinf(advantages)):
                    if verbose:
                        print(f"âš ï¸ NaN/Inf in {comp} advantages for conflict detection")
                    continue

                advantage_mean = np.mean(advantages)

                # æ£€æŸ¥å‡å€¼çš„æœ‰æ•ˆæ€§
                if np.isnan(advantage_mean) or np.isinf(advantage_mean):
                    if verbose:
                        print(f"âš ï¸ NaN/Inf in {comp} advantage mean")
                    continue

                advantage_means.append(advantage_mean)
                comp_names.append(comp)

                # åªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ›´æ–°å†å²æ•°æ®
                if not hasattr(self, '_current_update_processed'):
                    self.advantage_history[comp].append(advantage_mean)

            if len(advantage_means) < 2:
                return False

            # å¦‚æœå†å²æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å½“å‰æ•°æ®
            if len(self.advantage_history[comp_names[0]]) < 5:
                advantage_matrix = np.array([advantage_means])
            else:
                # ä½¿ç”¨å†å²æ•°æ®æ„å»ºçŸ©é˜µ
                advantage_matrix = []
                for comp in comp_names:
                    hist_data = list(self.advantage_history[comp])[-5:]
                    # æ£€æŸ¥å†å²æ•°æ®çš„æœ‰æ•ˆæ€§
                    if any(np.isnan(x) or np.isinf(x) for x in hist_data):
                        if verbose:
                            print(f"âš ï¸ NaN/Inf in {comp} history data")
                        continue
                    advantage_matrix.append(hist_data)

                if len(advantage_matrix) < 2:
                    return False

                advantage_matrix = np.array(advantage_matrix)

            if advantage_matrix.shape[0] < 2 or advantage_matrix.shape[1] < 2:
                return False

            # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
            try:
                corr_matrix = np.corrcoef(advantage_matrix)

                # æ£€æŸ¥ç›¸å…³ç³»æ•°çŸ©é˜µçš„æœ‰æ•ˆæ€§
                if np.any(np.isnan(corr_matrix)) or np.any(np.isinf(corr_matrix)):
                    if verbose:
                        print(f"âš ï¸ NaN/Inf in correlation matrix")
                    return False

            except Exception as e:
                if verbose:
                    print(f"âš ï¸ Error computing correlation matrix: {e}")
                return False

            # è®¡ç®—å¹¶è®°å½•æ‰€æœ‰äº¤å‰é¡¹çš„ç›¸å…³æ€§
            conflicts = 0
            severe_conflicts = 0
            conflict_pairs = []
            current_correlations = {}

            for i in range(len(comp_names)):
                for j in range(i + 1, len(comp_names)):
                    if i < corr_matrix.shape[0] and j < corr_matrix.shape[1]:
                        correlation = corr_matrix[i, j]
                        comp1, comp2 = comp_names[i], comp_names[j]

                        if not (np.isnan(correlation) or np.isinf(correlation)):
                            # è®°å½•å½“å‰ç›¸å…³æ€§
                            pair_key = f"{comp1}_{comp2}"
                            current_correlations[pair_key] = correlation

                            # æ›´æ–°ç›¸å…³æ€§å†å²
                            if not hasattr(self, '_current_update_processed'):
                                self.correlation_history[pair_key].append(correlation)

                            # åˆ¤æ–­å†²çªçº§åˆ«
                            if correlation < self.conflict_threshold:
                                conflicts += 1
                                severity = "severe" if correlation < self.severe_conflict_threshold else "moderate"
                                conflict_pairs.append((comp1, comp2, correlation, severity))

                            if correlation < self.severe_conflict_threshold:
                                severe_conflicts += 1

            # åªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ›´æ–°çŠ¶æ€å˜é‡
            if not hasattr(self, '_current_update_processed'):
                self.latest_conflicts = conflicts
                self.latest_severe_conflicts = severe_conflicts
                self.current_correlations = current_correlations
                self._current_update_processed = True

                # æ‰“å°æ‰€æœ‰äº¤å‰é¡¹çš„ç›¸å…³æ€§
                if verbose:
                    print(f"\nğŸ” Correlation Analysis:")
                    for pair in self.component_pairs:
                        pair_key = f"{pair[0]}_{pair[1]}"
                        correlation = current_correlations.get(pair_key, 0.0)

                        # åˆ¤æ–­çŠ¶æ€
                        if correlation < self.severe_conflict_threshold:
                            status = "ğŸš¨ SEVERE"
                        elif correlation < self.conflict_threshold:
                            status = "âš ï¸ MODERATE"
                        else:
                            status = "âœ… NORMAL"

                        print(f"   {pair[0]} vs {pair[1]}: {correlation:.3f} {status}")

                # åªåœ¨æœ‰å†²çªæ—¶æ‰“å°å†²çªæ‘˜è¦
                if conflicts > 0 and verbose:
                    print(f"\nâš ï¸ Multi-objective conflicts detected: {conflicts} total, {severe_conflicts} severe")
                    for comp1, comp2, corr, severity in conflict_pairs:
                        print(f"   ğŸš¨ {comp1} vs {comp2}: correlation = {corr:.3f} ({severity})")

            return conflicts > 0

        except Exception as e:
            if verbose:
                print(f"âš ï¸ Error detecting conflicts: {e}")
            return False

    def analyze_conflict_impact(self,
                               component_values: Dict[str, np.ndarray],
                               component_advantages: Dict[str, np.ndarray],
                               component_losses: Dict[str, float],
                               total_advantages: np.ndarray) -> Dict[str, float]:
        """ğŸ” æ–°å¢ï¼šåˆ†æå†²çªå¯¹ç­–ç•¥æ›´æ–°çš„å½±å“å æ¯”"""
        try:
            impact_metrics = {}

            # 1. Valueå½±å“åˆ†æ - å„åˆ†é‡valueçš„åˆ†æ­§ç¨‹åº¦
            if len(component_values) >= 2:
                value_means = [np.mean(vals) for vals in component_values.values()]
                value_std = np.std(value_means)
                value_mean = np.mean(value_means)
                # å½’ä¸€åŒ–çš„åˆ†æ­§ç¨‹åº¦
                value_divergence_ratio = value_std / (abs(value_mean) + 1e-8)
                impact_metrics['value_divergence_ratio'] = min(value_divergence_ratio, 1.0)
            else:
                impact_metrics['value_divergence_ratio'] = 0.0

            # 2. Advantageå†²çªåˆ†æ - ç¬¦å·ç›¸åçš„advantageå æ¯”
            if len(component_advantages) >= 2:
                adv_signs = []
                for comp, adv in component_advantages.items():
                    adv_mean = np.mean(adv)
                    adv_signs.append(1 if adv_mean > 0 else -1)

                # è®¡ç®—ç¬¦å·å†²çªæ¯”ä¾‹
                positive_count = sum(1 for sign in adv_signs if sign > 0)
                negative_count = len(adv_signs) - positive_count
                # å†²çªæ¯”ä¾‹ = min(æ­£è´Ÿæ•°é‡) / æ€»æ•°é‡
                conflict_ratio = min(positive_count, negative_count) / len(adv_signs)
                impact_metrics['advantage_conflict_ratio'] = conflict_ratio
            else:
                impact_metrics['advantage_conflict_ratio'] = 0.0

            # 3. Lossä¸ç¨³å®šæ€§åˆ†æ - lossçš„æ ‡å‡†å·®
            if len(component_losses) >= 2:
                loss_values = list(component_losses.values())
                loss_std = np.std(loss_values)
                loss_mean = np.mean([abs(l) for l in loss_values])
                # å½’ä¸€åŒ–çš„ä¸ç¨³å®šæ€§
                loss_instability_ratio = loss_std / (loss_mean + 1e-8)
                impact_metrics['loss_instability_ratio'] = min(loss_instability_ratio, 1.0)
            else:
                impact_metrics['loss_instability_ratio'] = 0.0

            # 4. æ¢¯åº¦å¹²æ‰°åˆ†æ - åŸºäºadvantageæ–¹å·®
            if len(component_advantages) >= 2:
                # è®¡ç®—å„åˆ†é‡advantageçš„æ–¹å·®
                adv_variances = [np.var(adv) for adv in component_advantages.values()]
                total_adv_variance = np.var(total_advantages) if total_advantages.size > 0 else 1e-8

                # åˆ†é‡æ–¹å·®çš„æ€»å’Œä¸æ€»ä½“æ–¹å·®çš„æ¯”å€¼
                component_var_sum = sum(adv_variances)
                interference_ratio = component_var_sum / (total_adv_variance + 1e-8)
                # å½’ä¸€åŒ–åˆ°[0,1]
                impact_metrics['gradient_interference_ratio'] = min(interference_ratio / len(component_advantages), 1.0)
            else:
                impact_metrics['gradient_interference_ratio'] = 0.0

            # 5. ç»¼åˆå½±å“å æ¯” - åŠ æƒå¹³å‡
            weights = [0.2, 0.3, 0.2, 0.3]  # value, advantage, loss, gradientçš„æƒé‡
            overall_impact = (
                weights[0] * impact_metrics['value_divergence_ratio'] +
                weights[1] * impact_metrics['advantage_conflict_ratio'] +
                weights[2] * impact_metrics['loss_instability_ratio'] +
                weights[3] * impact_metrics['gradient_interference_ratio']
            )
            impact_metrics['overall_impact_ratio'] = overall_impact

            # æ›´æ–°å®ä¾‹å˜é‡
            self.impact_metrics = impact_metrics

            return impact_metrics

        except Exception as e:
            print(f"âš ï¸ Error analyzing conflict impact: {e}")
            return {
                'value_divergence_ratio': 0.0,
                'advantage_conflict_ratio': 0.0,
                'loss_instability_ratio': 0.0,
                'gradient_interference_ratio': 0.0,
                'overall_impact_ratio': 0.0
            }

    def update_histories(self,
                        rewards_data: Dict[str, np.ndarray],
                        component_values: Dict[str, np.ndarray],
                        component_losses: Dict[str, float],
                        weights: Optional[np.ndarray]):
        """æ›´æ–°å†å²æ•°æ®"""
        try:
            for comp in self.components:
                # æ›´æ–°å¥–åŠ±å†å²
                if comp in rewards_data:
                    self.reward_history[comp].append(np.mean(rewards_data[comp]))

                # æ›´æ–°valueå†å²
                if comp in component_values:
                    self.value_history[comp].append(np.mean(component_values[comp]))

                # æ›´æ–°æŸå¤±å†å²
                if comp in component_losses:
                    self.loss_history[comp].append(component_losses[comp])

                # æ›´æ–°æƒé‡å†å²
                if weights is not None:
                    comp_idx = self.components.index(comp)
                    if comp_idx < weights.shape[-1]:
                        self.weight_history[comp].append(np.mean(weights[:, :, comp_idx]))

        except Exception as e:
            print(f"âš ï¸ Error updating histories: {e}")

    def log_to_tensorboard(self,
                          timestep: int,
                          component_values: Dict,
                          component_advantages: Dict,
                          component_losses: Dict,
                          rewards_data: Dict):
        """è®°å½•åˆ°tensorboard - å¢åŠ æ‰€æœ‰äº¤å‰é¡¹ç›¸å…³æ€§"""
        try:
            # è®°å½•å„åˆ†é‡çš„è¯¦ç»†æŒ‡æ ‡
            for comp in self.components:
                if comp in rewards_data:
                    self.writer.add_scalar(f'multi_objective/{comp}/reward_mean',
                                         np.mean(rewards_data[comp]), timestep)

                if comp in component_values:
                    self.writer.add_scalar(f'multi_objective/{comp}/value_mean',
                                         np.mean(component_values[comp]), timestep)

                if comp in component_advantages:
                    self.writer.add_scalar(f'multi_objective/{comp}/advantage_mean',
                                         np.mean(component_advantages[comp]), timestep)

                if comp in component_losses:
                    self.writer.add_scalar(f'multi_objective/{comp}/policy_loss',
                                         component_losses[comp], timestep)

            # è®°å½•æ‰€æœ‰äº¤å‰é¡¹ç›¸å…³æ€§åˆ°tensorboard
            for pair in self.component_pairs:
                pair_key = f"{pair[0]}_{pair[1]}"
                correlation = self.current_correlations.get(pair_key, 0.0)
                self.writer.add_scalar(f'multi_objective/correlations/{pair[0]}_vs_{pair[1]}',
                                     correlation, timestep)

            # è®°å½•å†²çªä¿¡æ¯
            self.writer.add_scalar('multi_objective/conflicts/total_conflicts', self.latest_conflicts, timestep)
            self.writer.add_scalar('multi_objective/conflicts/severe_conflicts', self.latest_severe_conflicts, timestep)

            # è®°å½•å½±å“åˆ†ææŒ‡æ ‡
            for metric_name, metric_value in self.impact_metrics.items():
                self.writer.add_scalar(f'multi_objective/impact/{metric_name}', metric_value, timestep)

        except Exception as e:
            print(f"âš ï¸ Error logging to tensorboard: {e}")

    def update(self, actor_buffer_list, critic_buffer, total_advantages, timestep: int = None, episode: int = None):
        """ä¸»è¦æ›´æ–°æ¥å£ - çœŸæ­£è®¡ç®—å„åˆ†é‡çš„valueã€advantageã€loss"""
        try:
            self.update_count += 1

            if not self.should_monitor():
                return False

            # é‡ç½®å½“å‰æ›´æ–°æ ‡è®°
            if hasattr(self, '_current_update_processed'):
                delattr(self, '_current_update_processed')

            # æå–åˆ†é‡æ•°æ®
            rewards_data, weights = self.extract_component_data(actor_buffer_list)

            # å¦‚æœæ²¡æœ‰çœŸå®çš„åˆ†é‡æ•°æ®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•
            if not rewards_data:
                episode_length = total_advantages.shape[0] if len(total_advantages.shape) > 0 else 100
                n_threads = total_advantages.shape[1] if len(total_advantages.shape) > 1 else 20

                rewards_data = {
                    'safety': np.random.randn(episode_length, n_threads, 1) * 0.1 + 0.5,
                    'efficiency': np.random.randn(episode_length, n_threads, 1) * 0.1 + 0.3,
                    'stability': np.random.randn(episode_length, n_threads, 1) * 0.1 + 0.3,
                    'comfort': np.random.randn(episode_length, n_threads, 1) * 0.1 + 0.1
                }

            # çœŸæ­£è®¡ç®—å„åˆ†é‡çš„returnsã€valueså’Œadvantages
            component_returns, component_values, component_advantages = self.compute_component_returns_and_advantages(
                rewards_data, critic_buffer, weights
            )

            if not component_advantages:
                return False

            # è®¡ç®—å„åˆ†é‡çš„ç­–ç•¥æŸå¤±
            component_losses = self.compute_component_losses(component_advantages)

            # åŸºäºçœŸå®advantageæ£€æµ‹å†²çªï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼‰
            conflicts_detected = self.detect_conflicts(component_advantages, verbose=True)

            # åˆ†æå†²çªå¯¹ç­–ç•¥æ›´æ–°çš„å½±å“
            impact_metrics = self.analyze_conflict_impact(
                component_values, component_advantages, component_losses, total_advantages
            )

            # æ›´æ–°å†å²æ•°æ®
            self.update_histories(rewards_data, component_values, component_losses, weights)

            # è®°å½•åˆ°tensorboard
            if timestep is not None:
                self.log_to_tensorboard(timestep, component_values, component_advantages, component_losses, rewards_data)

            # ä¿å­˜ç›¸å…³æ€§æ•°æ®åˆ°CSV
            if timestep is not None and episode is not None and self.save_dir:
                self._save_correlations_to_csv(timestep, episode)

            return conflicts_detected

        except Exception as e:
            print(f"âš ï¸ Multi-objective monitoring failed: {e}")
            return False

    def log_episode_summary(self, episode: int, total_timesteps: int):
        """episodeæ‘˜è¦ - å¢åŠ å½±å“åˆ†æ"""
        try:
            if len(self.advantage_history[self.components[0]]) == 0:
                return

            print(f"\nğŸ“Š Multi-Objective Analysis - Episode {episode}:")
            print(f"   ğŸš¨ Conflicts: {self.latest_conflicts} total, {self.latest_severe_conflicts} severe")

            # æ˜¾ç¤ºå„åˆ†é‡çš„è¯¦ç»†ä¿¡æ¯
            for comp in self.components:
                if len(self.advantage_history[comp]) > 0:
                    latest_advantage = self.advantage_history[comp][-1]
                    latest_reward = self.reward_history[comp][-1] if len(self.reward_history[comp]) > 0 else 0
                    latest_loss = self.loss_history[comp][-1] if len(self.loss_history[comp]) > 0 else 0

                    print(f"   ğŸ“ˆ {comp.capitalize()}: adv={latest_advantage:.3f}, "
                          f"reward={latest_reward:.3f}, loss={latest_loss:.3f}")

            # æ˜¾ç¤ºå½±å“åˆ†æ
            impact = self.impact_metrics
            print(f"   ğŸ¯ Policy Impact Analysis:")
            print(f"      â€¢ Value Divergence: {impact['value_divergence_ratio']:.3f}")
            print(f"      â€¢ Advantage Conflict: {impact['advantage_conflict_ratio']:.3f}")
            print(f"      â€¢ Loss Instability: {impact['loss_instability_ratio']:.3f}")
            print(f"      â€¢ Gradient Interference: {impact['gradient_interference_ratio']:.3f}")
            print(f"      â€¢ Overall Impact: {impact['overall_impact_ratio']:.3f}")

            # å†²çªè­¦å‘Š
            if self.latest_severe_conflicts > 0:
                print("   âš ï¸ SEVERE conflicts detected - immediate attention needed!")
            elif self.latest_conflicts > 0:
                print("   âš ï¸ Moderate conflicts detected - monitor closely")
            else:
                print("   âœ… No significant conflicts detected")

            # å½±å“ç¨‹åº¦è­¦å‘Š
            if impact['overall_impact_ratio'] > 0.7:
                print("   ğŸš¨ HIGH policy update interference detected!")
            elif impact['overall_impact_ratio'] > 0.4:
                print("   âš ï¸ Moderate policy update interference")
            else:
                print("   âœ… Low policy update interference")

        except Exception as e:
            print(f"âš ï¸ Error in episode summary: {e}")


class DummyMonitor:
    """ç©ºå®ç°"""
    def update(self, *args, **kwargs):
        return False
    def log_episode_summary(self, *args, **kwargs):
        pass


# ä¾¿æ·æ¥å£å‡½æ•°
def create_monitor(writer, monitor_freq: int = 5, save_dir: str = None):
    """åˆ›å»ºç›‘æµ‹å™¨"""
    return MultiObjectiveMonitor.create(writer, monitor_freq, save_dir)


def monitor_update(monitor, actor_buffer_list, critic_buffer, advantages, timestep=None, episode=None):
    """ç›‘æµ‹æ›´æ–°"""
    if hasattr(monitor, 'update'):
        return monitor.update(actor_buffer_list, critic_buffer, advantages, timestep, episode)
    return False


def log_summary(monitor, episode, total_timesteps):
    """è®°å½•æ‘˜è¦"""
    if hasattr(monitor, 'log_episode_summary'):
        monitor.log_episode_summary(episode, total_timesteps)